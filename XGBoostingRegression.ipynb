{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoosting Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CurrentAcres</th>\n",
       "      <th>TotalGrossArea</th>\n",
       "      <th>FinishedArea</th>\n",
       "      <th>CurrentLandValue</th>\n",
       "      <th>CurrentYardItemsValue</th>\n",
       "      <th>CurrentBuildingValue</th>\n",
       "      <th>Grade</th>\n",
       "      <th>YearBlt</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>NumofRooms</th>\n",
       "      <th>...</th>\n",
       "      <th>HeatType_188</th>\n",
       "      <th>HeatType_281</th>\n",
       "      <th>HeatType_739</th>\n",
       "      <th>HeatType_3893</th>\n",
       "      <th>HeatType_4255</th>\n",
       "      <th>Foundation_130</th>\n",
       "      <th>Foundation_1219</th>\n",
       "      <th>Foundation_2322</th>\n",
       "      <th>Foundation_2628</th>\n",
       "      <th>Foundation_3199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05597</td>\n",
       "      <td>1760</td>\n",
       "      <td>840.00000</td>\n",
       "      <td>121600</td>\n",
       "      <td>0</td>\n",
       "      <td>30900.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1912</td>\n",
       "      <td>158000</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.08242</td>\n",
       "      <td>2676</td>\n",
       "      <td>1436.00000</td>\n",
       "      <td>94400</td>\n",
       "      <td>700</td>\n",
       "      <td>146800.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1899</td>\n",
       "      <td>231750</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>2184</td>\n",
       "      <td>1572.80005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>268000.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1986</td>\n",
       "      <td>381500</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.09832</td>\n",
       "      <td>3699</td>\n",
       "      <td>2087.00000</td>\n",
       "      <td>130100</td>\n",
       "      <td>0</td>\n",
       "      <td>210700.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1910</td>\n",
       "      <td>430000</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.70154</td>\n",
       "      <td>62852</td>\n",
       "      <td>37977.00000</td>\n",
       "      <td>547700</td>\n",
       "      <td>51800</td>\n",
       "      <td>1306100.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2013</td>\n",
       "      <td>505683</td>\n",
       "      <td>103</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CurrentAcres  TotalGrossArea  FinishedArea  CurrentLandValue  \\\n",
       "0       0.05597            1760     840.00000            121600   \n",
       "1       0.08242            2676    1436.00000             94400   \n",
       "2       0.00000            2184    1572.80005                 0   \n",
       "3       0.09832            3699    2087.00000            130100   \n",
       "4       0.70154           62852   37977.00000            547700   \n",
       "\n",
       "   CurrentYardItemsValue  CurrentBuildingValue  Grade  YearBlt  SalePrice  \\\n",
       "0                      0               30900.0      5     1912     158000   \n",
       "1                    700              146800.0      7     1899     231750   \n",
       "2                      0              268000.0     10     1986     381500   \n",
       "3                      0              210700.0      8     1910     430000   \n",
       "4                  51800             1306100.0      9     2013     505683   \n",
       "\n",
       "   NumofRooms       ...         HeatType_188  HeatType_281  HeatType_739  \\\n",
       "0           5       ...                    0             0             0   \n",
       "1           7       ...                    0             0             0   \n",
       "2           6       ...                    0             0             0   \n",
       "3           8       ...                    0             0             0   \n",
       "4         103       ...                    0             0             0   \n",
       "\n",
       "   HeatType_3893  HeatType_4255  Foundation_130  Foundation_1219  \\\n",
       "0              1              0               0                0   \n",
       "1              0              1               0                0   \n",
       "2              0              1               0                1   \n",
       "3              1              0               0                0   \n",
       "4              0              1               0                1   \n",
       "\n",
       "   Foundation_2322  Foundation_2628  Foundation_3199  \n",
       "0                0                1                0  \n",
       "1                0                1                0  \n",
       "2                0                0                0  \n",
       "3                0                1                0  \n",
       "4                0                0                0  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feature = pd.read_csv('Ready_for_machine_learning_2019_1_23.csv')\n",
    "df_feature.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the target and variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_feature.drop(columns=['SalePrice'])\n",
    "y = df_feature.SalePrice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Train and Test sets, and perform scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\snowflakes\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Anaconda\\envs\\snowflakes\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Anaconda\\envs\\snowflakes\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoosting Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 10735538455.5438\n",
      "Square of MSE: 103612.4435\n",
      "Average Percentage of Abosulute Error: 0.2267\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "reg = xgb.XGBRegressor(random_state=0)\n",
    "reg.fit(X_train, y_train)\n",
    "mse = mean_squared_error(y_test, reg.predict(X_test))\n",
    "print(\"MSE: %.4f\" % mse)\n",
    "print(\"Square of MSE: %.4f\" % np.sqrt(mse))\n",
    "print(\"Average Percentage of Abosulute Error: %.4f\" % np.mean(np.abs(reg.predict(X_test)-y_test)/y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "feature_importance = reg.feature_importances_\n",
    "# make importances relative to max importance\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, X.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unable to read variable names. The following list the feature names from the least important to the most important. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BuildingType_81', 'BuildingType_60', 'Foundation_2628',\n",
       "       'BuildingType_83', 'BuildingType_87', 'BuildingType_101',\n",
       "       'BuildingType_103', 'BuildingType_108', 'BuildingType_110',\n",
       "       'BuildingType_111', 'BuildingType_147', 'BuildingType_219',\n",
       "       'BuildingType_291', 'BuildingType_338', 'BuildingType_482',\n",
       "       'BuildingType_589', 'BuildingType_1028', 'BuildingType_1193',\n",
       "       'Foundation_2322', 'Foundation_130', 'HeatType_3893', 'HeatType_739',\n",
       "       'HeatType_281', 'HeatType_188', 'BuildingType_46', 'HeatType_58',\n",
       "       'HeatFuel_8187', 'HeatFuel_1039', 'HeatFuel_281', 'HeatFuel_64',\n",
       "       'BuildingType_2168', 'BuildingType_1389', 'HeatType_50',\n",
       "       'BuildingType_44', 'Foundation_3199', 'BuildingType_31', 'LandUse_239',\n",
       "       'LandUse_367', 'LandUse_369', 'LandUse_1041', 'LandUse_2150',\n",
       "       'BuildingType_39', 'LandUse_8', 'BuildingType_12', 'BuildingType_14',\n",
       "       'BuildingType_22', 'BuildingType_24', 'BuildingType_30', 'LandUse_45',\n",
       "       'LandUse_5176', 'Foundation_1219', 'BuildingType_162', 'LandUse_43',\n",
       "       'BuildingType_9', 'HeatType_4255', 'BuildingType_298', 'LandUse_117',\n",
       "       'BuildingType_11', 'BuildingType_144', 'HeatType_54', 'BuildingType_8',\n",
       "       'CurrentYardItemsValue', 'Grade', 'NumofUnits', 'LandUse_285',\n",
       "       'PropertyCenterPoint_x', 'YearBlt', 'Depreciation', 'FinishedArea',\n",
       "       'NumofRooms', 'PropertyCenterPoint_y', 'TotalGrossArea',\n",
       "       'CurrentBuildingValue', 'CurrentLandValue', 'CurrentAcres'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns[sorted_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Among the most important features are 'CurrentAcres', 'CurrentLandValue', 'CurrentBuildingValue', 'TotalGrossArea', and 'PropertyCenterPoint_y' in the preliminary XGB regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The parameters of the XGB regression model will be tuned to established a better-fit model. We value MSE of the average percentage abosolute error since accuracy on the prediction of prices of high-valued housing properties are more important than those of low values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_est = 50\n",
      "max_depth = 1\n",
      "learning_rate = 0.1\n",
      "mse = 16167127322.1728\n",
      "ape = 0.5354\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 1\n",
      "learning_rate = 0.2\n",
      "mse = 12252411819.6430\n",
      "ape = 0.3591\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 1\n",
      "learning_rate = 0.3\n",
      "mse = 12045247498.9177\n",
      "ape = 0.2881\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 1\n",
      "learning_rate = 0.4\n",
      "mse = 13099250971.4062\n",
      "ape = 0.2794\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 1\n",
      "learning_rate = 0.5\n",
      "mse = 13224785868.1027\n",
      "ape = 0.2700\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 1\n",
      "learning_rate = 0.6\n",
      "mse = 12273361203.5991\n",
      "ape = 0.2740\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 1\n",
      "learning_rate = 0.7\n",
      "mse = 12528012702.9348\n",
      "ape = 0.2747\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 1\n",
      "learning_rate = 0.8\n",
      "mse = 12269906944.1566\n",
      "ape = 0.2491\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 1\n",
      "learning_rate = 0.9\n",
      "mse = 12491346702.5727\n",
      "ape = 0.2562\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 2\n",
      "learning_rate = 0.1\n",
      "mse = 12448524535.0419\n",
      "ape = 0.3655\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 2\n",
      "learning_rate = 0.2\n",
      "mse = 12004865880.7796\n",
      "ape = 0.2445\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 2\n",
      "learning_rate = 0.3\n",
      "mse = 11896638799.0231\n",
      "ape = 0.2292\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 2\n",
      "learning_rate = 0.4\n",
      "mse = 12103253977.2757\n",
      "ape = 0.2190\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 2\n",
      "learning_rate = 0.5\n",
      "mse = 12654243511.7216\n",
      "ape = 0.2114\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 2\n",
      "learning_rate = 0.6\n",
      "mse = 11880919441.6485\n",
      "ape = 0.2256\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 2\n",
      "learning_rate = 0.7\n",
      "mse = 14072654449.5319\n",
      "ape = 0.2143\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 2\n",
      "learning_rate = 0.8\n",
      "mse = 12593934827.9119\n",
      "ape = 0.2191\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 2\n",
      "learning_rate = 0.9\n",
      "mse = 14288597612.5588\n",
      "ape = 0.2134\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 3\n",
      "learning_rate = 0.1\n",
      "mse = 11118786637.5939\n",
      "ape = 0.2774\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 3\n",
      "learning_rate = 0.2\n",
      "mse = 10883777341.7172\n",
      "ape = 0.2270\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 3\n",
      "learning_rate = 0.3\n",
      "mse = 11998540305.8489\n",
      "ape = 0.2052\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 3\n",
      "learning_rate = 0.4\n",
      "mse = 11292107433.8699\n",
      "ape = 0.2087\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 3\n",
      "learning_rate = 0.5\n",
      "mse = 11233172112.4370\n",
      "ape = 0.2063\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 3\n",
      "learning_rate = 0.6\n",
      "mse = 12168128789.1925\n",
      "ape = 0.2132\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 3\n",
      "learning_rate = 0.7\n",
      "mse = 11690141205.8530\n",
      "ape = 0.2158\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 3\n",
      "learning_rate = 0.8\n",
      "mse = 13625910359.0779\n",
      "ape = 0.2197\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 3\n",
      "learning_rate = 0.9\n",
      "mse = 14117889584.5214\n",
      "ape = 0.2203\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 4\n",
      "learning_rate = 0.1\n",
      "mse = 10676697161.5509\n",
      "ape = 0.2354\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 4\n",
      "learning_rate = 0.2\n",
      "mse = 10709900112.3544\n",
      "ape = 0.2138\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 4\n",
      "learning_rate = 0.3\n",
      "mse = 11150212137.3405\n",
      "ape = 0.2046\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 4\n",
      "learning_rate = 0.4\n",
      "mse = 11048442688.1776\n",
      "ape = 0.2065\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 4\n",
      "learning_rate = 0.5\n",
      "mse = 11347993354.1732\n",
      "ape = 0.2046\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 4\n",
      "learning_rate = 0.6\n",
      "mse = 11506347577.9916\n",
      "ape = 0.2206\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 4\n",
      "learning_rate = 0.7\n",
      "mse = 12124209939.9164\n",
      "ape = 0.2147\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 4\n",
      "learning_rate = 0.8\n",
      "mse = 15002015831.6428\n",
      "ape = 0.2232\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 4\n",
      "learning_rate = 0.9\n",
      "mse = 14455379863.5183\n",
      "ape = 0.2312\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 5\n",
      "learning_rate = 0.1\n",
      "mse = 9792253168.8098\n",
      "ape = 0.2128\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 5\n",
      "learning_rate = 0.2\n",
      "mse = 10319496425.6813\n",
      "ape = 0.2026\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 5\n",
      "learning_rate = 0.3\n",
      "mse = 10408977585.6514\n",
      "ape = 0.2064\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 5\n",
      "learning_rate = 0.4\n",
      "mse = 13818471346.2225\n",
      "ape = 0.2136\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 5\n",
      "learning_rate = 0.5\n",
      "mse = 12260760735.7755\n",
      "ape = 0.2166\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 5\n",
      "learning_rate = 0.6\n",
      "mse = 11989595994.8093\n",
      "ape = 0.2246\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 5\n",
      "learning_rate = 0.7\n",
      "mse = 13431058214.9554\n",
      "ape = 0.2298\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 5\n",
      "learning_rate = 0.8\n",
      "mse = 15555716274.8977\n",
      "ape = 0.2311\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 5\n",
      "learning_rate = 0.9\n",
      "mse = 15625301459.6855\n",
      "ape = 0.2337\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 6\n",
      "learning_rate = 0.1\n",
      "mse = 9588769631.9871\n",
      "ape = 0.2054\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 6\n",
      "learning_rate = 0.2\n",
      "mse = 10300860893.3300\n",
      "ape = 0.2015\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 6\n",
      "learning_rate = 0.3\n",
      "mse = 10763170186.5638\n",
      "ape = 0.2074\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 6\n",
      "learning_rate = 0.4\n",
      "mse = 11058868702.1953\n",
      "ape = 0.2136\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 6\n",
      "learning_rate = 0.5\n",
      "mse = 13449218991.1285\n",
      "ape = 0.2289\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 6\n",
      "learning_rate = 0.6\n",
      "mse = 12270424314.5111\n",
      "ape = 0.2304\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 6\n",
      "learning_rate = 0.7\n",
      "mse = 13497839778.4945\n",
      "ape = 0.2308\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 6\n",
      "learning_rate = 0.8\n",
      "mse = 12799330923.8500\n",
      "ape = 0.2309\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 6\n",
      "learning_rate = 0.9\n",
      "mse = 15983238718.8627\n",
      "ape = 0.2462\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 7\n",
      "learning_rate = 0.1\n",
      "mse = 10161271093.3298\n",
      "ape = 0.2020\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 7\n",
      "learning_rate = 0.2\n",
      "mse = 10114058923.6727\n",
      "ape = 0.2079\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 7\n",
      "learning_rate = 0.3\n",
      "mse = 11211139618.6756\n",
      "ape = 0.2118\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 7\n",
      "learning_rate = 0.4\n",
      "mse = 11468995756.1755\n",
      "ape = 0.2105\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 7\n",
      "learning_rate = 0.5\n",
      "mse = 11500327457.4663\n",
      "ape = 0.2245\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 7\n",
      "learning_rate = 0.6\n",
      "mse = 13627937697.4738\n",
      "ape = 0.2311\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 7\n",
      "learning_rate = 0.7\n",
      "mse = 14131614507.9862\n",
      "ape = 0.2380\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 7\n",
      "learning_rate = 0.8\n",
      "mse = 15044357497.5629\n",
      "ape = 0.2478\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 7\n",
      "learning_rate = 0.9\n",
      "mse = 15790572292.4390\n",
      "ape = 0.2586\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 8\n",
      "learning_rate = 0.1\n",
      "mse = 9916244626.7852\n",
      "ape = 0.2066\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 8\n",
      "learning_rate = 0.2\n",
      "mse = 10366985547.6701\n",
      "ape = 0.2076\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 8\n",
      "learning_rate = 0.3\n",
      "mse = 10694113585.3975\n",
      "ape = 0.2151\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 8\n",
      "learning_rate = 0.4\n",
      "mse = 12046210563.6088\n",
      "ape = 0.2214\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 8\n",
      "learning_rate = 0.5\n",
      "mse = 11639595738.7054\n",
      "ape = 0.2368\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 8\n",
      "learning_rate = 0.6\n",
      "mse = 13627959405.5536\n",
      "ape = 0.2327\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 8\n",
      "learning_rate = 0.7\n",
      "mse = 13301717114.9528\n",
      "ape = 0.2295\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 8\n",
      "learning_rate = 0.8\n",
      "mse = 12638543292.8446\n",
      "ape = 0.2424\n",
      "__________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_est = 50\n",
      "max_depth = 8\n",
      "learning_rate = 0.9\n",
      "mse = 14880892982.8719\n",
      "ape = 0.2524\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 9\n",
      "learning_rate = 0.1\n",
      "mse = 10307578898.0458\n",
      "ape = 0.2030\n",
      "__________________________________\n",
      "n_est = 50\n",
      "max_depth = 9\n",
      "learning_rate = 0.2\n",
      "mse = 10166277105.1094\n",
      "ape = 0.2064\n",
      "__________________________________\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-ca094981e94a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlearning\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mLearning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mreg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_est\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[0mmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\snowflakes\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[0;32m    371\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 373\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\snowflakes\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[0;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\snowflakes\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\snowflakes\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1043\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[1;32m-> 1045\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m   1046\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initial model \n",
    "reg0 = xgb.XGBRegressor(random_state=0)\n",
    "reg0.fit(X_train, y_train)\n",
    "mse0 = mean_squared_error(y_test, reg0.predict(X_test))\n",
    "ape0 = np.mean(np.abs(reg0.predict(X_test)-y_test)/y_test)\n",
    "\n",
    "# Initialize the best model and parameters\n",
    "bestreg = reg0\n",
    "bestmse = mse0\n",
    "bestape = ape0\n",
    "best_n_est = 100 # default\n",
    "bestdepth = 3 # default\n",
    "bestlearning = 0.1 # default\n",
    " \n",
    "# Search for the best model(in terms of smallest mse)  \n",
    "N_est = np.arange(50,125,25)\n",
    "Depth = np.arange(1,11,1)\n",
    "Learning = np.arange(0.1,1,0.1) \n",
    "for n_est in N_est: \n",
    "    for d in Depth:\n",
    "        for learning in Learning:\n",
    "            reg = xgb.XGBRegressor(max_depth=d, learning_rate=learning, n_estimators=n_est)\n",
    "            reg.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(y_test, reg.predict(X_test))\n",
    "            ape = np.mean(np.abs(reg.predict(X_test)-y_test)/y_test)            \n",
    "            print(\"n_est = %.0f\" % n_est)\n",
    "            print(\"max_depth = %.0f\" % d)\n",
    "            print(\"learning_rate = %.1f\" % learning)\n",
    "            print(\"mse = %.4f\" % mse)\n",
    "            print(\"ape = %.4f\" % ape)\n",
    "            print(\"__________________________________\")\n",
    "            if mse<bestmse: \n",
    "                bestreg = reg\n",
    "                bestmse = mse\n",
    "                bestape = ape ## This might not be the smallest ape among all models but is the ape of the best model(in terms of smallest mse)\n",
    "                best_n_est = n_est\n",
    "                bestdepth = d\n",
    "                bestlearning = learning\n",
    "\n",
    "print(\"best n_estimators = %.0f\" % best_n_est)           \n",
    "print(\"best max_depth = %.0f\" % bestdepth)\n",
    "print(\"best learning = %.1f\" % bestlearning)\n",
    "print(\"best mse = %.4f\" % bestmse)\n",
    "print(\"best ape = %.4f\" % bestape)  ## This might not be the smallest ape among all models but is the ape of the best model(in terms of smallest mse)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Continue Searching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for the best model(in terms of smallest mse)  \n",
    "N_est = np.arange(125,225,25)\n",
    "Depth = np.arange(1,11,1)\n",
    "Learning = np.arange(0.1,1,0.1) \n",
    "for n_est in N_est: \n",
    "    for d in Depth:\n",
    "        for learning in Learning:\n",
    "            reg = xgb.XGBRegressor(max_depth=d, learning_rate=learning, n_estimators=n_est)\n",
    "            reg.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(y_test, reg.predict(X_test))\n",
    "            ape = np.mean(np.abs(reg.predict(X_test)-y_test)/y_test)            \n",
    "            print(\"n_est = %.0f\" % n_est)\n",
    "            print(\"max_depth = %.0f\" % d)\n",
    "            print(\"learning_rate = %.1f\" % learning)\n",
    "            print(\"mse = %.4f\" % mse)\n",
    "            print(\"ape = %.4f\" % ape)\n",
    "            print(\"__________________________________\")\n",
    "            if mse<bestmse: \n",
    "                bestreg = reg\n",
    "                bestmse = mse\n",
    "                bestape = ape ## This might not be the smallest ape among all models but is the ape of the best model(in terms of smallest mse)\n",
    "                best_n_est = n_est\n",
    "                bestdepth = d\n",
    "                bestlearning = learning\n",
    "\n",
    "print(\"best n_estimators = %.0f\" % best_n_est)           \n",
    "print(\"best max_depth = %.0f\" % bestdepth)\n",
    "print(\"best learning = %.1f\" % bestlearning)\n",
    "print(\"best mse = %.4f\" % bestmse)\n",
    "print(\"best ape = %.4f\" % bestape)  ## This might not be the smallest ape among all models but is the ape of the best model(in terms of smallest mse)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continue Searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for the best model(in terms of smallest mse)  \n",
    "N_est = np.arange(225,325,25)\n",
    "Depth = np.arange(1,11,1)\n",
    "Learning = np.arange(0.1,1,0.1) \n",
    "for n_est in N_est: \n",
    "    for d in Depth:\n",
    "        for learning in Learning:\n",
    "            reg = xgb.XGBRegressor(max_depth=d, learning_rate=learning, n_estimators=n_est)\n",
    "            reg.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(y_test, reg.predict(X_test))\n",
    "            ape = np.mean(np.abs(reg.predict(X_test)-y_test)/y_test)            \n",
    "            print(\"n_est = %.0f\" % n_est)\n",
    "            print(\"max_depth = %.0f\" % d)\n",
    "            print(\"learning_rate = %.1f\" % learning)\n",
    "            print(\"mse = %.4f\" % mse)\n",
    "            print(\"ape = %.4f\" % ape)\n",
    "            print(\"__________________________________\")\n",
    "            if mse<bestmse: \n",
    "                bestreg = reg\n",
    "                bestmse = mse\n",
    "                bestape = ape ## This might not be the smallest ape among all models but is the ape of the best model(in terms of smallest mse)\n",
    "                best_n_est = n_est\n",
    "                bestdepth = d\n",
    "                bestlearning = learning\n",
    "\n",
    "print(\"best n_estimators = %.0f\" % best_n_est)           \n",
    "print(\"best max_depth = %.0f\" % bestdepth)\n",
    "print(\"best learning = %.1f\" % bestlearning)\n",
    "print(\"best mse = %.4f\" % bestmse)\n",
    "print(\"best ape = %.4f\" % bestape)  ## This might not be the smallest ape among all models but is the ape of the best model(in terms of smallest mse)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Continue Searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for the best model(in terms of smallest mse)  \n",
    "N_est = np.arange(325,425,25)\n",
    "Depth = np.arange(1,11,1)\n",
    "Learning = np.arange(0.1,1,0.1) \n",
    "for n_est in N_est: \n",
    "    for d in Depth:\n",
    "        for learning in Learning:\n",
    "            reg = xgb.XGBRegressor(max_depth=d, learning_rate=learning, n_estimators=n_est)\n",
    "            reg.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(y_test, reg.predict(X_test))\n",
    "            ape = np.mean(np.abs(reg.predict(X_test)-y_test)/y_test)            \n",
    "            print(\"n_est = %.0f\" % n_est)\n",
    "            print(\"max_depth = %.0f\" % d)\n",
    "            print(\"learning_rate = %.1f\" % learning)\n",
    "            print(\"mse = %.4f\" % mse)\n",
    "            print(\"ape = %.4f\" % ape)\n",
    "            print(\"__________________________________\")\n",
    "            if mse<bestmse: \n",
    "                bestreg = reg\n",
    "                bestmse = mse\n",
    "                bestape = ape ## This might not be the smallest ape among all models but is the ape of the best model(in terms of smallest mse)\n",
    "                best_n_est = n_est\n",
    "                bestdepth = d\n",
    "                bestlearning = learning\n",
    "\n",
    "print(\"best n_estimators = %.0f\" % best_n_est)           \n",
    "print(\"best max_depth = %.0f\" % bestdepth)\n",
    "print(\"best learning = %.1f\" % bestlearning)\n",
    "print(\"best mse = %.4f\" % bestmse)\n",
    "print(\"best ape = %.4f\" % bestape)  ## This might not be the smallest ape among all models but is the ape of the best model(in terms of smallest mse)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Continue Searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for the best model(in terms of smallest mse)  \n",
    "N_est = np.arange(425,525,25)\n",
    "Depth = np.arange(1,11,1)\n",
    "Learning = np.arange(0.1,1,0.1) \n",
    "for n_est in N_est: \n",
    "    for d in Depth:\n",
    "        for learning in Learning:\n",
    "            reg = xgb.XGBRegressor(max_depth=d, learning_rate=learning, n_estimators=n_est)\n",
    "            reg.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(y_test, reg.predict(X_test))\n",
    "            ape = np.mean(np.abs(reg.predict(X_test)-y_test)/y_test)            \n",
    "            print(\"n_est = %.0f\" % n_est)\n",
    "            print(\"max_depth = %.0f\" % d)\n",
    "            print(\"learning_rate = %.1f\" % learning)\n",
    "            print(\"mse = %.4f\" % mse)\n",
    "            print(\"ape = %.4f\" % ape)\n",
    "            print(\"__________________________________\")\n",
    "            if mse<bestmse: \n",
    "                bestreg = reg\n",
    "                bestmse = mse\n",
    "                bestape = ape ## This might not be the smallest ape among all models but is the ape of the best model(in terms of smallest mse)\n",
    "                best_n_est = n_est\n",
    "                bestdepth = d\n",
    "                bestlearning = learning\n",
    "\n",
    "print(\"best n_estimators = %.0f\" % best_n_est)           \n",
    "print(\"best max_depth = %.0f\" % bestdepth)\n",
    "print(\"best learning = %.1f\" % bestlearning)\n",
    "print(\"best mse = %.4f\" % bestmse)\n",
    "print(\"best ape = %.4f\" % bestape)  ## This might not be the smallest ape among all models but is the ape of the best model(in terms of smallest mse)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We have searched through models with n_estimators ranging from 50 to 500 with a step increase of 25, max_depth from 1 to 10 and learning rate from 0.1 to 0.9 with a step increase of 0.1. The model with the smallest MSE is the model with n_estimator = 50, max_depth = 6, learning rate =0.1. The MSE of this model is 9588769631.9871. The average pertange of absolulte deviation is 20.54%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the feature importance of the model with the smallest MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Intialize the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 9588769631.9871\n",
      "Square of MSE: 97922.2632\n",
      "Average Percentage of Abosulute Error: 0.2054\n"
     ]
    }
   ],
   "source": [
    "reg = xgb.XGBRegressor(max_depth=6, learning_rate=0.1, n_estimators=50, random_state=0)\n",
    "reg.fit(X_train, y_train)\n",
    "mse = mean_squared_error(y_test, reg.predict(X_test))\n",
    "print(\"MSE: %.4f\" % mse)\n",
    "print(\"Square of MSE: %.4f\" % np.sqrt(mse))\n",
    "print(\"Average Percentage of Abosulute Error: %.4f\" % np.mean(np.abs(reg.predict(X_test)-y_test)/y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The following list the feature names from the least important to the most important. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BuildingType_81', 'BuildingType_30', 'BuildingType_31',\n",
       "       'BuildingType_39', 'BuildingType_44', 'BuildingType_46',\n",
       "       'BuildingType_60', 'Foundation_2628', 'BuildingType_83',\n",
       "       'BuildingType_101', 'BuildingType_103', 'BuildingType_108',\n",
       "       'BuildingType_110', 'BuildingType_111', 'BuildingType_147',\n",
       "       'BuildingType_162', 'BuildingType_219', 'BuildingType_482',\n",
       "       'BuildingType_589', 'BuildingType_1389', 'HeatFuel_1039',\n",
       "       'HeatFuel_8187', 'HeatType_50', 'HeatType_58', 'HeatType_281',\n",
       "       'Foundation_130', 'BuildingType_24', 'BuildingType_22',\n",
       "       'Foundation_3199', 'BuildingType_12', 'BuildingType_11',\n",
       "       'BuildingType_8', 'LandUse_2150', 'BuildingType_14', 'LandUse_367',\n",
       "       'LandUse_8', 'LandUse_43', 'HeatType_188', 'HeatFuel_281',\n",
       "       'BuildingType_1028', 'BuildingType_338', 'BuildingType_87',\n",
       "       'BuildingType_9', 'LandUse_369', 'LandUse_1041', 'LandUse_5176',\n",
       "       'LandUse_239', 'BuildingType_2168', 'LandUse_45', 'Foundation_1219',\n",
       "       'HeatType_739', 'HeatType_4255', 'BuildingType_291', 'Foundation_2322',\n",
       "       'HeatType_3893', 'BuildingType_1193', 'LandUse_117', 'HeatFuel_64',\n",
       "       'LandUse_285', 'HeatType_54', 'BuildingType_144', 'BuildingType_298',\n",
       "       'NumofUnits', 'CurrentYardItemsValue', 'NumofRooms', 'Grade', 'YearBlt',\n",
       "       'FinishedArea', 'Depreciation', 'PropertyCenterPoint_y',\n",
       "       'PropertyCenterPoint_x', 'CurrentAcres', 'TotalGrossArea',\n",
       "       'CurrentLandValue', 'CurrentBuildingValue'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance = reg.feature_importances_\n",
    "# make importances relative to max importance\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "X.columns[sorted_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 'Grade', 'YearBlt', 'FinishedArea', 'Depreciation', 'PropertyCenterPoint_y', 'PropertyCenterPoint_x', 'CurrentAcres', 'TotalGrossArea','CurrentLandValue', 'CurrentBuildingValue' are among the most important features of the full model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To plot a visible feature importance bar chart, we need to take a few top listed features and establish a simplied model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Establish a simplified model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\snowflakes\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Anaconda\\envs\\snowflakes\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Anaconda\\envs\\snowflakes\\lib\\site-packages\\ipykernel_launcher.py:13: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 9540009587.4448\n",
      "Square of MSE: 97672.9727\n",
      "Average Percentage of Abosulute Error: 0.2048\n"
     ]
    }
   ],
   "source": [
    "X2=df_feature[['LandUse_117', 'HeatFuel_64',\n",
    "       'LandUse_285', 'HeatType_54', 'BuildingType_144', 'BuildingType_298',\n",
    "       'NumofUnits', 'CurrentYardItemsValue', 'NumofRooms', 'Grade', 'YearBlt',\n",
    "       'FinishedArea', 'Depreciation', 'PropertyCenterPoint_y',\n",
    "       'PropertyCenterPoint_x', 'CurrentAcres', 'TotalGrossArea',\n",
    "       'CurrentLandValue', 'CurrentBuildingValue']]\n",
    "y2=df_feature.SalePrice\n",
    "from sklearn.model_selection import train_test_split\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=0)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X2_train = scaler.fit_transform(X2_train)\n",
    "X2_test = scaler.transform(X2_test)\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "reg = xgb.XGBRegressor(max_depth=6, learning_rate=0.1, n_estimators=50, random_state=0)\n",
    "reg.fit(X2_train, y2_train)\n",
    "mse = mean_squared_error(y2_test, reg.predict(X2_test))\n",
    "print(\"MSE: %.4f\" % mse)\n",
    "print(\"Square of MSE: %.4f\" % np.sqrt(mse))\n",
    "print(\"Average Percentage of Abosulute Error: %.4f\" % np.mean(np.abs(reg.predict(X2_test)-y2_test)/y2_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have a better model in XGBoosting! I think this is due to the fact that the default regression method in XGB is linear regression. Linear Regression has the nature of taking the most relevant features instead of incorporating the other less important features will result in a better fit regression model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "feature_importance = reg.feature_importances_\n",
    "# make importances relative to max importance\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, X2.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simplified XGB model gives the best estimation result. This models takes features:'LandUse_117', 'HeatFuel_64','LandUse_285', 'HeatType_54', 'BuildingType_144', 'BuildingType_298','NumofUnits', 'CurrentYardItemsValue', 'NumofRooms', 'Grade', 'YearBlt','FinishedArea', 'Depreciation', 'PropertyCenterPoint_y','PropertyCenterPoint_x', 'CurrentAcres', 'TotalGrossArea','CurrentLandValue', 'CurrentBuildingValue'.  It has MSE: 9540009587.4448 and the Average Percentage of Abosulute Error: 20.48%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
